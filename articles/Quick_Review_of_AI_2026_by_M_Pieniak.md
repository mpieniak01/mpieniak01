# AI in the Sociological Perspective – 2026
## A Quick Review of AI 2025/2026

Figure 1 – Concept of the human–AI competence model: from knowledge automation to intention design

**Date:** Warsaw, January 20, 2026
**Author:** Maciej Pieniak
**Original Publication:** [AI in the Sociological Perspective – 2026](https://www.linkedin.com/pulse/ai-sociological-perspective-2026-maciej-pieniak-b8sof/)
**Proofreading:** Gemini 3 and ChatGPT 5.2

## Introduction
Welcome back after more than a year   In 2024, I published a series of three popular-science articles
in which I gradually built my own concept of an AI Assistant. As a short reminder:
- In “To Use AI or Not to Use AI”, I proposed my own definition of an AI Assistant (consumer AI)
— as a system with specific functions and responsibilities, not just the ability to generate
content, and capable of pursuing different goals depending on user needs.
- In “Is AI Intelligent?”, I analyzed perception, decision-making processes, reasoning, and the
dynamics of model behavior.
- In “Ethics in AI”, I asked whether AI can pursue goals when multiple criteria exist at the same
time — and, most importantly, whose goals these should be.
That trilogy was a starting point for further reflection and described the possibilities and limitations of
AI technology as of 2024. Today, the natural next question is: how wide can AI’s impact on society be?
This article is dedicated to that question.
Before analyzing social impacts, it is worth starting with a short summary of 2025, from the perspective
of AI development.

## 2025 — A Summary of AI Trends
As I predicted, 2025 brought dynamic progress in several key areas.
1. Law and Regulation
2025 was the year when regulations began to realistically organize the AI market. For users, this meant
less “anything goes” and more rules and responsibility.
Previously developed legal concepts entered a phase of real-world testing. As a result, we have seen —
and will continue to see — many disputes and court cases. A large part of them concern decisions made
years earlier, especially in the area of model training. The logic of “let’s do it now and see later who
proves it was illegal” turned out to be short-sighted.
At the same time, concrete protective mechanisms appeared in some areas, such as age verification or
restrictions on access to sensitive content. In practice, this means one thing: AI stopped being an
unframed experiment and became part of digital infrastructure — with accountability.

2. The User Ecosystem
AI is no longer just a “chat window.” It has become an integral part of the user’s ecosystem — from
working with documents and email, through office task automation, to advisory functions and the
generation of images and short video formats.
The most fundamental change, however, concerns context. AI assistants now operate based on
interaction history and user preferences. The importance of carefully crafted system prompts is steadily
decreasing — interaction becomes naturally contextual.

Classic search engines, based on lists of links, are being replaced by conversational data analysis. In
practice, this creates a meta-search layer.

3. Model Technology
Models are simultaneously gaining reasoning abilities and becoming lighter. Thanks to distillation and
compression, computing power moves closer to the user — faster, cheaper, and locally.
This leads to a key shift: the advantage is no longer access to technology itself, but how it is used.

4. The Social Aspect
— and this is where things become most interesting …
### Social Awareness — Scale of AI Adoption
Some indicative data on AI adoption:
- Globally, about one-third of the world’s population knows the term “AI”.
- In countries such as India and Nigeria, over 90% of the population actively uses AI.
- In China — 83%.
- In Poland — as many as 70% of people use AI regularly (often without their employer’s
knowledge).
- In Poland, only 6% of companies have implemented AI in business operations, placing the
country at the bottom of the region.
The data comes from late 2025 from experimental studies (“Global AI Popularity Indicators”) using
Deep Research tools (Gemini / ChatGPT). I treat it as unverified, but an interesting signal of trends.
AI became a global phenomenon faster than electricity or the Internet. The scale and speed of
adoption have no historical precedent. Adoption is progressing faster in lower-income countries than
in wealthy ones.
I assume that the social consequences of these trends will become clearly visible already in 2026.

## Law and Responsibility
It becomes crucial to clearly define the rules of digital representation of an AI Assistant and the scope
of its autonomy. My position remains unchanged: the author is the user, and AI is a tool.
The system does not have — and should not have — legal personality.
A key vector in this discussion is data: both user data and data used by AI systems. I assume, by default,
that both streams are obtained legally — without t

Only on such a foundation — with clear separation of roles, data, and responsibility — can meaningful
discussions about transparency and legal consequences of AI use take place. I hope that 2026 will bring
further clarification in this area.

## Education in the Age of AI
Changes in education systems are ongoing. Below, I present an illustrative example of the direction in
which — in my opinion — this change should go.
Modern education systems are still largely based on the so-called Prussian school model — focused
on storing structured, clearly defined knowledge in students’ memory. In a world of information
overload and rapidly changing cognitive contexts, this approach is losing its purpose.
AI, as an extension of human intelligence, challenges the need to memorize large sets of data that are
themselves temporary. It is worth noting that even advanced knowledge models — such as Gemini or
GPT — can already be inaccurate due to domain knowledge models becoming outdated.
This situation encourages reflection on a new teaching paradigm. Instead of repeated drills aimed at
efficiency in many narrow areas — often serving only to “pass” and move to the next educational level
— education could focus on building a coherent, interdisciplinary knowledge model.
Such a model allows faster movement to higher levels of abstraction and returning to concrete issues
only when truly needed. Skill development can happen individually, according to interests and natural
predispositions.
An example of knowledge currently under revision? The Pythagorean theorem. It is taught and
repeated at every stage of education. The total time spent learning and practicing it across a population
amounts to millions of hours.
In practice, only a small fraction of society uses it. The world around us is mostly based on rectangles
and circles. Personally, the last time I faced a “triangle problem” was several years ago when cutting a
piece of carpet — I solved it by tracing the shape, not by mathematical calculation.
Of course, many calculations are triangle-based, but with modern progress, this knowledge becomes
increasingly specialized and should be reinforced in specialist education, not general schooling.
Dividing knowledge into siloed subjects is a very human solution, but — as AI model design shows —
not an optimal one. In AI models, school subjects or domains are just labels, while relationships
between objects are built across multiple dimensions.
This is one reason why people struggle to answer questions phrased differently from learned formulas,
while AI can adapt context to the way a question is asked.

## “We Don’t Know” — Clarified Logically
A common error is treating lack of evidence as evidence of a result, rather than as a cognitive state.
Other errors include:
- assuming only two possible states: yes or no,
- accepting one of them as binding without justification.

- Meanwhile, “we don’t know” is often the most accurate cognitive state.
This is another paradigm that needs to change:
- moving away from binary yes/no logic toward discrete state logic.
- Unlearning habits formed since childhood, such as automatically applying the “natural
distribution” heuristic and treating 50% risk as consensus when knowledge is missing.
- “We don’t know, but we can assume” is a natural starting point for exploration — as long as,
over time, this assumption is not silently replaced with a claim.
Interestingly, this approach can reduce “hallucinations” on both sides — human and AI.

## Example of a Task in a New Educational Paradigm
“Calculate how many blocks are needed to build a bridge between two banks of a drawn river.
You may use AI assistance, but no longer than 10 minutes — that’s how long your phone battery lasts.
Then build the bridge using the planned number of blocks. Finally, present your work and justify why
you used that number of blocks. You may work in pairs.”
In this approach, as AI becomes widespread, key competencies will include:
- designing experiments and precisely defining concepts,
- building knowledge, including creating one’s own classification methods,
- critical and systems thinking,
- problem solving and decision making.
In the long term — optimistically — I assume that the democratization of knowledge may increase
the dynamics of the Flynn effect (growth of average IQ) by genuinely supporting cognitive processes.

## The Labor Market and AI
AI will accelerate the rotation of roles we are used to in various industries. This will bring real social
consequences.
The cost of automating routine tasks has dropped dramatically, opening space for further process
optimization.
From the employee’s perspective:
- change becomes permanent, and professional mobility becomes the norm,
- automation first targets repetitive, stagnant tasks when economically justified,
- responsibility increases, along with the importance o

The labor market will be one of the most interesting areas of upcoming change, shaped by many factors
beyond AI itself. I leave this topic open, limiting myself to two perspectives: a thought experiment and
a historical analogy.
Thought experiment:
If all organizations implement the same highest level of AI — what remains a source of competitive
advantage?
→ My answer: the human factor.
Historical analogy:
In the 19th century, people feared that railways would stop cows from producing milk and that
humans would suffocate at “dizzying” speeds.
Today, we view these fears with distance — and it is possible that current fears about AI will be seen
similarly.

## Pace of Change
In technological and social evolution, two extreme attitudes toward change can be identified, strongly
influencing the pace and manner of adaptation.
- Revolution — a rapid, significant change in a short time. History shows that revolutions often
come with high adaptation costs: conflict, losses, and the risk of distorting the original goals.
- Kaizen — an approach based on continuous, evolutionary improvement. In medicine, it is
sometimes defined as the smallest change fully acceptable to the patient.
Between these poles lies a wide spectrum of change-management methods.
Media calling AI development a “revolution” does not directly translate into the real pace or scope of
changes inside specific organizations. The choice between a sudden breakthrough and gradual
improvement remains an autonomous organizational decision, based on strategy.

## Cognitive Utopia
Even though I consciously live in my own information bubble, sometimes something reaches me. For
example:
“Today we will talk to an AI Expert about the best methods of breastfeeding.”
I mention trends and changes in thinking, but I am far from cognitive utopia. AI is not a single field, but
a technological conglomerate processing different types of data (knowledge). Meaningful statements
come from domain specialists on specific topics — not from an abstract “AI Expert”.
I do not even know whether the “AI Expert” mentioned above was a person who could write a prompt,
or an AI Agent instance speaking with a human voice.
For me, critical and systems thinking still applies. Let’s not assume someone can think for us.
In this sense, the “AI Expert” becomes a symbol of cognitive utopia — an attempt to shift responsibility
for thinking from oneself to an external authority, and in the AI context — from a human to a tool.

## Summary
The maturity of general-purpose AI agents — in my definition, AI Assistants — such as ChatGPT or
Google Gemini, has reached a satisfactory level. From the 2024 perspective, the scale and pace of
development turned out to be even greater than I originally expected.
At the end of 2025, a new layer of specialized agents appeared — such as GitHub Copilot, Codex GPT,
or Antigravity (Google) — which I have been intensively testing for several months. They show in
practice how AI can influence specific work processes — a topic I will return to in future articles.
2025 can be summarized as the closure of a technological phase. 2026 will be the beginning of a
deeper, AI-based transformation, which I see as a vector sum of phenomena only outlined in this
article.
“This article is a synthesis of my own explorations and reflections developed during postgraduate
studies ‘Digital Transformation and AI’ at Kozminski University.”
